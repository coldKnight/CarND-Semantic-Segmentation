[//]: # (Image References)
[lane-image]: ./runs/1504262773.4239352/umm_000012.png
[animated-output]: ./runs/1504262773.4239352/anim_road.gif

[image-um3]: ./training_sample/images/um_000003.png
[image-um5]: ./training_sample/images/um_000005.png
[image-umm3]: ./training_sample/images/umm_000003.png
[image-umm5]: ./training_sample/images/umm_000005.png
[image-uu3]: ./training_sample/images/uu_000003.png
[image-uu5]: ./training_sample/images/uu_000005.png
[image-uu75]: ./training_sample/images/uu_000075.png
[image-uu76]: ./training_sample/images/uu_000076.png

[gtimage-um3]: ./training_sample/gt_images/um_lane_000003.png
[gtimage-um5]: ./training_sample/gt_images/um_lane_000005.png
[gtimage-umm3]: ./training_sample/gt_images/umm_road_000003.png
[gtimage-umm5]: ./training_sample/gt_images/umm_road_000005.png
[gtimage-uu3]: ./training_sample/gt_images/uu_road_000003.png
[gtimage-uu5]: ./training_sample/gt_images/uu_road_000005.png
[gtimage-uu75]: ./training_sample/gt_images/uu_road_000075.png
[gtimage-uu76]: ./training_sample/gt_images/uu_road_000076.png


# Semantic Segmentation with Fully Convolutional Network (FCN)

### Introduction
The aim of this project is to understand the concepts of Fully Convolutional Network (FCN) and write a program to label the pixels of a road in images.

The results of the run are present in the logsData file. The test images are in the `runs` folder.

Examples of the training images:

Original Camera Image   |  Ground truth generated by manual annotation
:----------------------:|:--------------------------------------------:
![alt-text][image-um3]  | ![alt-text][gtimage-um3]
![alt-text][image-um5]  | ![alt-text][gtimage-um5]
![alt-text][image-umm3]  | ![alt-text][gtimage-umm3]
![alt-text][image-umm5]  | ![alt-text][gtimage-umm5]
![alt-text][image-uu3]  | ![alt-text][gtimage-uu3]
![alt-text][image-uu5]  | ![alt-text][gtimage-uu5]
![alt-text][image-uu75]  | ![alt-text][gtimage-uu75]
![alt-text][image-uu76]  | ![alt-text][gtimage-uu76]

---

### Output: 

![alt text][animated-output]

---

### Setup

#### Dataset
Download the [Kitti Road dataset](http://www.cvlibs.net/datasets/kitti/eval_road.php) from [here](http://www.cvlibs.net/download.php?file=data_road.zip).  Extract the dataset in the `data` folder.  This will create the folder `data_road` with all the training a test images.

 This benchmark has been created in collaboration with Jannik Fritsch and Tobias Kuehnl from [Honda Research Institute Europe GmbH](http://www.honda-ri.de/tiki-index.php?page=Welcome). The road and lane estimation benchmark consists of 289 training and 290 test images. It contains three different categories of road scenes:
- uu - urban unmarked (98/100)
- um - urban marked (95/96)
- umm - urban multiple marked lanes (96/94)
- urban - combination of the three above

#### Frameworks and Packages
Make sure you have the following is installed:
 - [Python 3](https://www.python.org/)
 - [TensorFlow](https://www.tensorflow.org/)
 - [NumPy](http://www.numpy.org/)
 - [SciPy](https://www.scipy.org/)

#### Run
Run the following command to run the project:
```
python main.py
```
**Note** If running this in Jupyter Notebook system messages, such as those regarding test status, may appear in the terminal rather than the notebook.

 ##### How to write a README
[A good guide](https://www.udacity.com/course/writing-readmes--ud777).
